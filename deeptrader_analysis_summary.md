# DeepTrader 行為分析結果

## 分析概述
使用 RandomForestClassifier 多標籤分類分析 DeepTrader 的股票選擇行為，採用統計特徵方法保留時間結構，實現真正的訓練/測試分割，了解哪些特徵最影響投資組合決策。

## 資料結構與降維過程

### 原始資料維度
- **stocks_data.npy**: (30支成分股, 2782個時間點, 34個特徵)
- **訓練資料來源**: val_results.json (37個trading steps)
- **測試資料來源**: test_results.json (33個trading steps)

### 降維過程詳解
```python
# 每個step的處理流程：
# Step 1: 提取時間窗口
原始: (30, 2782, 34)
窗口: stocks_data[:, input_start:input_end, :] → (30, 70, 34)

# Step 2: 對成分股軸取平均 (關鍵降維)
平均: np.mean(window_data, axis=0) → (70, 34)
# 假設: 市場整體狀態影響選股決策，避免71,400維的維度災難

# Step 3: 計算7種時間統計特徵 (保留時間結構)
Mean: np.mean(window_features, axis=0) → (34,)  # 70天均值
Std:  np.std(window_features, axis=0)  → (34,)  # 70天標準差  
Min:  np.min(window_features, axis=0)  → (34,)  # 70天最小值
Max:  np.max(window_features, axis=0)  → (34,)  # 70天最大值
T-1:  window_features[-1]              → (34,)  # 最近一天
T-5:  window_features[-5]              → (34,)  # 5天前
T-10: window_features[-10]             → (34,)  # 10天前

# Step 4: 合併統計特徵
最終: np.concatenate(time_stats) → (7×34=238,)
```

### 最終資料維度
- **訓練集 X**: (37 steps, 238 features) = (37, 7種統計量 × 34特徵)
- **測試集 X**: (33 steps, 238 features) = (33, 7種統計量 × 34特徵)
- **訓練集 Y**: (37 steps, 11 stocks) 二元向量 (過濾掉從未被選中的19支)
- **測試集 Y**: (33 steps, 11 stocks) 二元向量 (對應訓練集選出的股票)
- **平均每步選股數**: 4.00 檔

### MultiOutputClassifier 架構解析

```
輸入X: (37 steps, 238 features)
          ↓
    MultiOutputClassifier
          ↓
┌─────────────────────────────────────────────┐
│ Stock 0  │ Stock 1  │ Stock 2  │ ... │ Stock 10 │
│   RF     │   RF     │   RF     │ ... │    RF    │
│(100 trees)│(100 trees)│(100 trees)│ ... │(100 trees)│
└─────────────────────────────────────────────┘
          ↓ 獨立二元分類
    [0/1, 0/1, 0/1, ..., 0/1]
```

**關鍵特性**：
- **11個獨立的RandomForest**：每支股票一個分類器
- **獨立預測**：每個分類器輸出0或1 
- **feature_importances_**：每個分類器 (238,) 維度，加總=1.0
- **選股數不固定**：預測結果可能是2~6支股票，無法保證剛好4支

**⚠️ 重要限制**：與真實DeepTrader（固定選4支）不同，此方法選股數會變動。

## 股票選擇統計 (訓練/測試分割結果)

在訓練集(37步)中，**11支股票**曾被選中；測試集(33步)中**10支股票**曾被選中：

| 股票ID | 訓練集選擇頻率 | 測試集選擇頻率 | 測試準確率 | 泛化表現 |
|--------|---------------|---------------|-----------|----------|
| Stock 22 | 78.38% | 78.79% | 78.8% | 優秀 ⭐⭐⭐ |
| Stock 4  | 75.68% | 75.76% | 75.8% | 優秀 ⭐⭐⭐ |
| Stock 2  | 72.97% | 66.67% | 69.7% | 良好 ⭐⭐ |
| Stock 27 | 62.16% | 60.61% | 45.5% | 一般 ⭐ |
| Stock 0  | 54.05% | 60.61% | 45.5% | 一般 ⭐ |
| Stock 20 | 32.43% | 33.33% | 69.7% | 良好 ⭐⭐ |
| Stock 6  | 5.41%  | 15.15% | 45.5% | 差 |
| Stock 28 | 2.70%  | 3.03%  | 97.0% | 優秀 ⭐⭐⭐ |
| Stock 5  | 2.70%  | 3.03%  | 97.0% | 優秀 ⭐⭐⭐ |
| Stock 24 | 8.11%  | 0.00%  | 100% | 過擬合 |
| Stock 26 | 5.41%  | 0.00%  | 100% | 過擬合 |

## 特徵重要性分析 (訓練/測試分割結果)

### 模型性能 (RandomForestClassifier)
- **分類器**: MultiOutputClassifier with RandomForestClassifier
- **訓練集 Hamming Loss**: 0.0000 (完美分類)
- **測試集 Hamming Loss**: 0.2507 (合理的泛化誤差)
- **整體泛化能力**: 中等，存在一定過擬合但可接受

### 特徵重要性計算原理

#### 數據結構說明
```python
# MultiOutputClassifier 架構
11個獨立分類器 (對應11支被選中的股票)
│
├── Stock 0:  RandomForestClassifier → feature_importances_ (238,) 加總=1.0
├── Stock 2:  RandomForestClassifier → feature_importances_ (238,) 加總=1.0  
├── Stock 4:  RandomForestClassifier → feature_importances_ (238,) 加總=1.0
├── ...
└── Stock 28: RandomForestClassifier → feature_importances_ (238,) 加總=1.0

# 收集所有重要性: importances_list.shape = (11, 238)
```

#### 平均與重組過程
```python
# Step 1: 跨分類器平均 (保持特徵重要性歸一化性質)
avg_importances = np.mean(importances_list, axis=0)  # (238,)
# 結果: np.sum(avg_importances) = 1.0 (仍然歸一化)

# Step 2: 重組為統計量×特徵矩陣
importance_matrix = avg_importances.reshape(7, 34)  # (7統計量, 34特徵)
# 形狀: [Mean, Std, Min, Max, T-1, T-5, T-10] × [Feature0~33]

# Step 3: 計算統計量重要性 (對34特徵求和)
stat_importance = np.sum(importance_matrix, axis=1)  # (7,)
# 意義: 每種統計量在所有34特徵上的總貢獻度

# Step 4: 計算特徵重要性 (對7統計量求和)  
feature_importance = np.sum(importance_matrix, axis=0)  # (34,)
# 意義: 每個特徵在所有7統計量下的總貢獻度

# Step 5: 分析各統計量下的重要特徵差異
for i, stat_name in enumerate(stat_names):
    top_feats_for_stat = np.argsort(importance_matrix[i, :])[::-1][:3]
    # 找出每個統計量下最重要的前3個特徵
    # importance_matrix[i, :] 是第i個統計量在34個特徵上的重要性分布
```

#### 重要性解讀邏輯
- **統計量重要性**: 衡量每種時間統計量(Mean/Std/T-1等)的整體預測能力
- **特徵重要性**: 衡量每個原始特徵(Alpha101因子等)的整體預測能力  
- **特徵×統計量交互**: 揭示不同時間維度下哪些特徵最關鍵
- **三重視角**: 時間維度(何時重要) + 特徵維度(什麼重要) + 交互效應(何時何特徵最重要)

### 時間統計量重要性分析 (基於訓練集特徵重要性)
1. **T-1**: 0.1839 - 前一天的值最關鍵 🔥
2. **T-5**: 0.1759 - 5天前的值次之 🔥
3. **Mean**: 0.1706 - 70天均值重要 
4. **Std**: 0.1371 - 70天標準差 
5. **T-10**: 0.1259 - 10天前的值
6. **Min**: 0.1191 - 70天最小值
7. **Max**: 0.0876 - 70天最大值 (最不重要)

**關鍵發現**: 近期值(T-1, T-5)比長期統計量更重要，符合金融市場的短期動量特性。

### 最重要的10個特徵 (跨所有統計量)
1. **Feature 20**: 0.0570 - 最關鍵特徵 🎯
2. **Feature 14**: 0.0453 
3. **Feature 27**: 0.0427 
4. **Feature 33**: 0.0415 
5. **Feature 17**: 0.0405 
6. **Feature 28**: 0.0404 
7. **Feature 25**: 0.0397 
8. **Feature 7**: 0.0386 
9. **Feature 24**: 0.0375 
10. **Feature 19**: 0.0368 

### 各統計量下的重要特徵差異
- **Mean (70天均值)**: Features 20, 22, 28 最重要
- **Std (70天標準差)**: Features 17, 20, 7 最重要  
- **Min (70天最小值)**: Features 14, 28, 33 最重要
- **Max (70天最大值)**: Features 24, 20, 31 最重要
- **T-1 (前一天)**: Features 25, 20, 7 最重要 🔥
- **T-5 (5天前)**: Features 27, 28, 17 最重要 🔥
- **T-10 (10天前)**: Features 27, 21, 19 最重要

**觀察**: Feature 20在多個統計量下都很重要，是核心判別特徵；近期值(T-1, T-5)有獨特的特徵偏好。

## 關鍵發現 (訓練/測試分割版本)

1. **真實泛化性能**: 
   - 訓練集: 完美分類 (Hamming Loss = 0.0000)
   - 測試集: 合理泛化誤差 (Hamming Loss = 0.2507)  
   - 個股差異大: Stock 22, 4泛化佳；Stock 0, 27較差

2. **選股集中度與穩定性**: 
   - 僅37%的股票(11/30)會被訓練集選中，30%在測試集被選中
   - 核心穩定股票: Stock 22 (78.4%→78.8%), Stock 4 (75.7%→75.8%)
   - 過擬合風險: Stock 24, 26在訓練集被選但測試集為0

3. **降維策略有效性**:
   ```
   原始71,400維 → 對成分股取平均 → 統計特徵 → 238維
   (30×70×34)  → (70×34)           → (7×34)  → 效率提升300倍
   ```

4. **時間敏感性發現**: 
   - **短期動量主導**: T-1天(0.1839) > T-5天(0.1759) > 長期統計
   - **符合金融直覺**: 近期價格變動比長期均值更能預測選股
   - **統計量排序**: T-1 > T-5 > Mean > Std > T-10 > Min > Max

5. **特徵識別突破**: 
   - **核心特徵**: Feature 20 (0.0570) 在多個統計量下都重要
   - **時間特異性**: T-1看重Features 25,20,7；T-5看重Features 27,28,17
   - **特徵多樣性**: 不同統計量有不同的判別邏輯

6. **方法學優勢與限制**:
   - ✅ 真正的out-of-sample測試驗證泛化能力
   - ✅ RandomForestClassifier對小樣本友善，避免過度調參  
   - ✅ 統計特徵方法保留時間結構且高效
   - ❌ **選股數不固定**: 預測2~6支股票，與真實DeepTrader(固定4支)不同

## 實務建議

1. **重點監控特徵**: 
   - 優先關注Feature 20, 14, 27, 33（重要性>0.04）
   - 確認這些特徵的金融意義（技術指標？基本面？）

2. **時間窗口優化**: 
   - 考慮增加T-2, T-3天的特徵（填補T-1和T-5間的空隙）
   - 減少Max統計量的權重（重要性最低）

3. **選股策略調整**: 
   - 核心持股: Stock 22, 4 泛化能力強，可增加權重
   - 警惕股票: Stock 0, 27 泛化較差，需降低依賴
   - 避免Stock 24, 26（過擬合風險高）

4. **模型改進方向**: 
   - 增加訓練樣本數量以降低過擬合
   - 考慮ensemble方法結合多個時間窗口
   - 加入正則化防止對訓練集過度記憶

5. **選股數量控制**: 
   - **Top-K後處理**: 預測概率後選擇Top-4最高分股票
   - **Learning-to-Rank**: 改用排序方法直接預測相對重要性
   - **閾值調整**: 動態調整分類閾值使平均選股數接近4
   - **混合方法**: 結合二元分類和排序損失函數

6. **驗證測試**: 
   - 在更多時間段驗證Feature 20的穩定性  
   - 測試T-1, T-5特徵的跨市場一致性