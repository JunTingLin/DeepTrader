{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Data Preparing](https://github.com/CMACH508/DeepTrader?tab=readme-ov-file#data-preparing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                    File_name                     |                  shape                   |                  description                   |\n",
    "| :----------------------------------------------: | :--------------------------------------: | :--------------------------------------------: |\n",
    "|                 stocks_data.npy                  | [num_stocks, num_days, num_ASU_features] |       the inputs for asset scoring unit        |\n",
    "|                 market_data.npy                  |       [num_days, num_MSU_features]       |     the inputs for marketing scoring unit      |\n",
    "|                     ror.npy                      |          [num_stocks, num_days]          | rate of return file for calculating the return |\n",
    "| relation_file (e.g. industry_classification.npy) |         [num_stocks, num_stocks]         |     the relation matrix used in GCN layer      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2330.TW', '2454.TW', '2317.TW', '2382.TW', '2308.TW', '2303.TW', '2891.TW', '3711.TW', '2881.TW', '2412.TW', '2886.TW', '2882.TW', '2884.TW', '1216.TW', '2885.TW', '3231.TW', '3034.TW', '2357.TW', '2002.TW', '2892.TW', '1303.TW', '5880.TW', '2379.TW', '1301.TW', '2890.TW', '3008.TW', '3037.TW', '2345.TW', '5871.TW', '3661.TW', '2880.TW', '2327.TW', '2883.TW', '2301.TW', '1101.TW', '2887.TW', '2207.TW', '4938.TW', '6669.TW', '1326.TW', '3045.TW', '2395.TW', '5876.TW', '2603.TW', '1590.TW', '2912.TW', '4904.TW', '2801.TW', '6505.TW', '2408.TW']\n",
      "Total stocks to process: 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "TWII = \"^TWII\"\n",
    "toptw = pd.read_excel(r'0050.xlsx')\n",
    "TWII_STOCKS = [str(symbol) + '.TW' for symbol in toptw['Symbol']]\n",
    "print(TWII_STOCKS)\n",
    "print(f\"Total stocks to process: {len(TWII_STOCKS)}\")\n",
    "\n",
    "\n",
    "# Define a small epsilon to avoid 0 values after normalization\n",
    "EPSILON = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWII earliest date: 1997-07-02 00:00:00+08:00\n",
      "TWII Stocks earliest dates:\n",
      "2330.TW: 2000-01-04 00:00:00+08:00\n",
      "2454.TW: 2001-07-23 00:00:00+08:00\n",
      "2317.TW: 1993-01-05 00:00:00+08:00\n",
      "2382.TW: 2000-01-04 00:00:00+08:00\n",
      "2308.TW: 2000-01-04 00:00:00+08:00\n",
      "2303.TW: 2000-01-04 00:00:00+08:00\n",
      "2891.TW: 2002-05-17 00:00:00+08:00\n",
      "3711.TW: 2000-01-04 00:00:00+08:00\n",
      "2881.TW: 2001-12-20 00:00:00+08:00\n",
      "2412.TW: 2000-11-15 00:00:00+08:00\n",
      "2886.TW: 2000-01-04 00:00:00+08:00\n",
      "2882.TW: 2000-01-04 00:00:00+08:00\n",
      "2884.TW: 2002-01-29 00:00:00+08:00\n",
      "1216.TW: 2000-01-04 00:00:00+08:00\n",
      "2885.TW: 2000-01-04 00:00:00+08:00\n",
      "3231.TW: 2003-08-19 00:00:00+08:00\n",
      "3034.TW: 2002-08-27 00:00:00+08:00\n",
      "2357.TW: 2000-01-04 00:00:00+08:00\n",
      "2002.TW: 2000-01-04 00:00:00+08:00\n",
      "2892.TW: 2003-01-03 00:00:00+08:00\n",
      "1303.TW: 2000-01-04 00:00:00+08:00\n",
      "5880.TW: 2000-01-04 00:00:00+08:00\n",
      "2379.TW: 2000-01-04 00:00:00+08:00\n",
      "1301.TW: 2000-01-04 00:00:00+08:00\n",
      "2890.TW: 2000-01-04 00:00:00+08:00\n",
      "3008.TW: 2002-03-11 00:00:00+08:00\n",
      "3037.TW: 2000-01-04 00:00:00+08:00\n",
      "2345.TW: 2000-01-04 00:00:00+08:00\n",
      "5871.TW: 2011-12-13 00:00:00+08:00\n",
      "3661.TW: 2012-10-05 00:00:00+08:00\n",
      "2880.TW: 2001-12-20 00:00:00+08:00\n",
      "2327.TW: 2000-01-04 00:00:00+08:00\n",
      "2883.TW: 2001-12-31 00:00:00+08:00\n",
      "2301.TW: 2000-01-04 00:00:00+08:00\n",
      "1101.TW: 2000-01-04 00:00:00+08:00\n",
      "2887.TW: 2002-02-19 00:00:00+08:00\n",
      "2207.TW: 2000-01-04 00:00:00+08:00\n",
      "4938.TW: 2009-01-12 00:00:00+08:00\n",
      "6669.TW: 2017-11-13 00:00:00+08:00\n",
      "1326.TW: 2000-01-04 00:00:00+08:00\n",
      "3045.TW: 2002-08-27 00:00:00+08:00\n",
      "2395.TW: 2000-01-04 00:00:00+08:00\n",
      "5876.TW: 2014-09-25 00:00:00+08:00\n",
      "2603.TW: 2000-01-04 00:00:00+08:00\n",
      "1590.TW: 2010-12-13 00:00:00+08:00\n",
      "2912.TW: 2000-01-04 00:00:00+08:00\n",
      "4904.TW: 2005-08-24 00:00:00+08:00\n",
      "2801.TW: 2000-01-04 00:00:00+08:00\n",
      "6505.TW: 2003-12-26 00:00:00+08:00\n",
      "2408.TW: 2000-08-18 00:00:00+08:00\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Get the earliest available date for the TWII index\n",
    "twii_ticker = yf.Ticker(TWII)\n",
    "twii_history = twii_ticker.history(period=\"max\")\n",
    "if not twii_history.empty:\n",
    "    twii_earliest_date = twii_history.index.min()\n",
    "    print(\"TWII earliest date:\", twii_earliest_date)\n",
    "else:\n",
    "    print(\"No historical data found for TWII.\")\n",
    "\n",
    "# Get the earliest available date for each stock in TWII_STOCKS\\\n",
    "# Create a Tickers object for multiple stocks\n",
    "twii_tickers = yf.Tickers(\" \".join(TWII_STOCKS))\n",
    "\n",
    "# Dictionary to hold each stock's earliest date\n",
    "stocks_earliest_dates = {}\n",
    "\n",
    "for stock in TWII_STOCKS:\n",
    "    ticker = twii_tickers.tickers[stock]\n",
    "    stock_history = ticker.history(period=\"max\")\n",
    "    if not stock_history.empty:\n",
    "        earliest_date = stock_history.index.min()\n",
    "        stocks_earliest_dates[stock] = earliest_date\n",
    "    else:\n",
    "        stocks_earliest_dates[stock] = None\n",
    "\n",
    "print(\"TWII Stocks earliest dates:\")\n",
    "for stock, date in stocks_earliest_dates.items():\n",
    "    print(f\"{stock}: {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 22\n",
      "2001 20\n",
      "2002 16\n",
      "2003 9\n",
      "2004 7\n",
      "2005 7\n",
      "2006 6\n",
      "2007 6\n",
      "2008 6\n",
      "2009 6\n",
      "2010 5\n",
      "2011 4\n",
      "2012 3\n",
      "2013 2\n",
      "2014 2\n",
      "2015 1\n",
      "2016 1\n",
      "2017 1\n",
      "2018 0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "for i in range(2000, 2019):\n",
    "\tstocks_to_remove = []\n",
    "\ttarget_date = datetime.date(i, 1, 10)\n",
    "\tfor stock, dt in stocks_earliest_dates.items():\n",
    "\t\tif dt is None or dt.replace(tzinfo=None).date() > target_date:\n",
    "\t\t\tstocks_to_remove.append(stock)\n",
    "\t# print(\"Stocks to remove:\", stocks_to_remove)\n",
    "\tprint(str(i) + \" \" + str(len(stocks_to_remove)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocks to remove: ['6669.TW']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "stocks_to_remove = []\n",
    "target_date = datetime.date(2015, 1, 4)\n",
    "for stock, dt in stocks_earliest_dates.items():\n",
    "\tif dt is None or dt.replace(tzinfo=None).date() > target_date:\n",
    "\t\tstocks_to_remove.append(stock)\n",
    "print(\"Stocks to remove:\", stocks_to_remove)\n",
    "print(len(stocks_to_remove))\n",
    "\n",
    "for stock in stocks_to_remove:\n",
    "\tif stock in TWII_STOCKS:\n",
    "\t\tTWII_STOCKS.remove(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DIR = \".\"\n",
    "# Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "# PERIOD = \"10y\"\n",
    "START_DATE = \"2015-01-01\"\n",
    "END_DATE = \"2025-03-31\"\n",
    "# Open, High, Low, Close, Volume, Dividends, Stock Splits\n",
    "ASSET_FEATURES = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "MARKET_FEATURES = [\"Open\", \"High\", \"Low\", \"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total business days: 2673\n",
      "\n",
      "Training:\n",
      "  Start Index = 0\n",
      "  End Index = 1303\n",
      "  Total Business Days = 1304\n",
      "\n",
      "Validation:\n",
      "  Start Index = 1304\n",
      "  End Index = 2086\n",
      "  Total Business Days = 783\n",
      "\n",
      "Test:\n",
      "  Start Index = 2087\n",
      "  End Index = 2672\n",
      "  Total Business Days = 586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate business days for the fixed date range\n",
    "business_days = pd.bdate_range(start=START_DATE, end=END_DATE)\n",
    "print(\"Total business days:\", len(business_days))\n",
    "print()\n",
    "\n",
    "intervals = {\n",
    "    \"Training\": (\"2015/01/01\", \"2019/12/31\"),\n",
    "    \"Validation\": (\"2020/01/01\", \"2022/12/31\"),\n",
    "    \"Test\": (\"2023/01/01\", \"2025/03/31\"),\n",
    "}\n",
    "for interval_name, (start_date, end_date) in intervals.items():\n",
    "    interval_days = pd.bdate_range(start=start_date, end=end_date)\n",
    "    start_idx = business_days.get_loc(interval_days[0])  # find the start index\n",
    "    end_idx = business_days.get_loc(interval_days[-1])   # find the end index\n",
    "    total_days = len(interval_days)  # calculate the total number of business days\n",
    "    \n",
    "    print(f\"{interval_name}:\")\n",
    "    print(f\"  Start Index = {start_idx}\")\n",
    "    print(f\"  End Index = {end_idx}\")\n",
    "    print(f\"  Total Business Days = {total_days}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stocks_data.npy\n",
    "| File_name | Shape | Description |\n",
    "| ---- | ---- | ---- |\n",
    "|stocks_data.npy |\t[num_stocks, num_days, num_ASU_features] |\tthe inputs for asset scoring unit |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 2673, 5)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "\n",
    "stocks_data = []\n",
    "\n",
    "# Process each stock\n",
    "for stock in TWII_STOCKS:\n",
    "    ticker = yf.Ticker(stock)\n",
    "    # Download historical data for the given date range\n",
    "    df = ticker.history(start=START_DATE, end=END_DATE)[ASSET_FEATURES]\n",
    "    \n",
    "    # Remove timezone information from the index to match the naive date_range\n",
    "    df.index = df.index.tz_localize(None)\n",
    "    # Reindex to the fixed business day range\n",
    "    df = df.reindex(business_days)\n",
    "    \n",
    "    # Check missing values: count total NaN / total (rows x columns)\n",
    "    total_cells = df.shape[0] * df.shape[1]\n",
    "    nan_count = df.isna().sum().sum()\n",
    "    nan_ratio = nan_count / total_cells\n",
    "    if nan_ratio > 0.1:\n",
    "        print(f\"Warning: {stock} has {nan_ratio:.2%} missing values.\")\n",
    "    \n",
    "    # Fill missing values using forward fill, then backward fill if necessary\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "    df.ffill(inplace=True)\n",
    "    df.bfill(inplace=True)\n",
    "    \n",
    "    # # normalization per column\n",
    "    # for feature in ASSET_FEATURES:\n",
    "    #     min_val = df[feature].min()\n",
    "    #     max_val = df[feature].max()\n",
    "    #     # Standard min-max normalization, then shift the scale\n",
    "    #     df[feature] = ((df[feature] - min_val) / (max_val - min_val)) * (1 - EPSILON) + EPSILON\n",
    "    \n",
    "    stocks_data.append(df)\n",
    "\n",
    "# Convert list of DataFrames to numpy array with shape (number_of_stocks, number_of_days, number_of_features)\n",
    "stocks_data_np = np.stack([df.values for df in stocks_data])\n",
    "print(stocks_data_np.shape)\n",
    "\n",
    "np.save(f\"{TARGET_DIR}/stocks_data.npy\", stocks_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# market_data.npy\n",
    "| File_name | Shape | Description |\n",
    "| ---- | ---- | ---- |\n",
    "| market_data.npy | [num_days, num_MSU_features] | the inputs for marketing scoring unit |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download TWII historical data for the given date range\n",
    "ticker = yf.Ticker(TWII)\n",
    "market_data = ticker.history(start=START_DATE, end=END_DATE)[MARKET_FEATURES]\n",
    "\n",
    "# save to csv\n",
    "market_data.to_csv(f\"{TARGET_DIR}/^TWII.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2673, 4)\n"
     ]
    }
   ],
   "source": [
    "# Remove timezone information from the index so it matches the naive date_range\n",
    "market_data.index = market_data.index.tz_localize(None)\n",
    "# Reindex the DataFrame to the fixed business day range\n",
    "market_data = market_data.reindex(business_days)\n",
    "\n",
    "# Check missing values: calculate total cells and NaN ratio\n",
    "total_cells = market_data.shape[0] * market_data.shape[1]\n",
    "nan_count = market_data.isna().sum().sum()\n",
    "nan_ratio = nan_count / total_cells\n",
    "if nan_ratio > 0.1:\n",
    "    print(f\"Warning: TWII has {nan_ratio:.2%} missing values.\")\n",
    "\n",
    "# Fill missing values using forward fill, then backward fill if necessary\n",
    "market_data.replace(0, np.nan, inplace=True)\n",
    "market_data.ffill(inplace=True)\n",
    "market_data.bfill(inplace=True)\n",
    "\n",
    "# # Normalize each column (feature)\n",
    "# for feature in MARKET_FEATURES:\n",
    "#     min_val = market_data[feature].min()\n",
    "#     max_val = market_data[feature].max()\n",
    "#     # Standard min-max normalization, then shift the scale\n",
    "#     market_data[feature] = ((market_data[feature] - min_val) / (max_val - min_val)) * (1 - EPSILON) + EPSILON\n",
    "    \n",
    "# Convert the DataFrame to a numpy array and save it\n",
    "market_data_np = market_data.to_numpy()\n",
    "print(market_data_np.shape)\n",
    "np.save(f\"{TARGET_DIR}/market_data.npy\", market_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ror.py\n",
    "| File_name | Shape | Description |\n",
    "| ---- | ---- | ---- |\n",
    "| ror.npy | [num_stocks, num_days] | rate of return file for calculating the return|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 2673)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dictionary to collect rate of return series for each stock\n",
    "ror_data = {}\n",
    "\n",
    "# Process each stock in TWII_STOCKS\n",
    "for stock in TWII_STOCKS:\n",
    "    ticker = yf.Ticker(stock)\n",
    "    # Download historical data for the given date range\n",
    "    data = ticker.history(start=START_DATE, end=END_DATE)\n",
    "    \n",
    "    # Remove timezone info from the index so that it matches the naive date_range\n",
    "    data.index = data.index.tz_localize(None)\n",
    "    \n",
    "    # Reindex to the fixed business day range (if a date is missing, NaN is inserted)\n",
    "    data = data.reindex(business_days)\n",
    "    \n",
    "    # Check missing values: count total cells and compute NaN ratio\n",
    "    total_cells = data.shape[0] * data.shape[1]\n",
    "    nan_count = data.isna().sum().sum()\n",
    "    nan_ratio = nan_count / total_cells\n",
    "    if nan_ratio > 0.1:\n",
    "        print(f\"Warning: {stock} has {nan_ratio:.2%} missing values in raw data.\")\n",
    "    \n",
    "    # Fill missing values using forward fill, then backward fill if necessary\n",
    "    data.ffill(inplace=True)\n",
    "    data.bfill(inplace=True)\n",
    "    \n",
    "    # Compute daily rate of return: (Close / Open) - 1.0\n",
    "    ror_series = data[\"Close\"] / data[\"Open\"] - 1.0\n",
    "    ror_data[stock] = ror_series\n",
    "\n",
    "# Create a DataFrame with rows = stocks, columns = dates\n",
    "ror_df = pd.DataFrame(ror_data).transpose()\n",
    "print(ror_df.shape)  # Should be (num_stocks, num_days)\n",
    "\n",
    "# Save the numpy array (shape: [num_stocks, num_days])\n",
    "np.save(f\"{TARGET_DIR}/ror.npy\", ror_df.to_numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relation_file\n",
    "| File_name | Shape | Description |\n",
    "| ---- | ---- | ---- |\n",
    "| relation_file (e.g. industry_classification.npy) | [num_stocks, num_stocks] | the relation matrix used in GCN layer|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT-industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Basic Materials': {'2002.TW', '1326.TW', '1101.TW', '1301.TW', '1303.TW'},\n",
      " 'Consumer Cyclical': {'2207.TW'},\n",
      " 'Consumer Defensive': {'1216.TW', '2912.TW'},\n",
      " 'Financial Services': {'2801.TW',\n",
      "                        '2882.TW',\n",
      "                        '2885.TW',\n",
      "                        '2886.TW',\n",
      "                        '2890.TW',\n",
      "                        '5880.TW'},\n",
      " 'Industrials': {'2603.TW'},\n",
      " 'Technology': {'2301.TW',\n",
      "                '2303.TW',\n",
      "                '2308.TW',\n",
      "                '2317.TW',\n",
      "                '2327.TW',\n",
      "                '2330.TW',\n",
      "                '2345.TW',\n",
      "                '2357.TW',\n",
      "                '2379.TW',\n",
      "                '2382.TW',\n",
      "                '2395.TW',\n",
      "                '3037.TW',\n",
      "                '3711.TW'}}\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create a Tickers object for multiple stocks in TWII_STOCKS\n",
    "twii_tickers = yf.Tickers(\" \".join(TWII_STOCKS))\n",
    "\n",
    "# Build a dictionary to map each sector to a set of stocks in that sector\n",
    "industry = defaultdict(set)\n",
    "for stock in twii_tickers.symbols:\n",
    "    ticker = twii_tickers.tickers[stock]\n",
    "    # Extract sector information from ticker.info; assume it exists\n",
    "    sector = ticker.info.get('sector')\n",
    "    if sector is not None:\n",
    "        industry[sector].add(stock)\n",
    "\n",
    "# Print the industry classification dictionary for reference\n",
    "pprint(dict(industry))\n",
    "\n",
    "# Build the relation matrix based on industry classification\n",
    "industry_classification = []\n",
    "for stock in twii_tickers.symbols:\n",
    "    ticker = twii_tickers.tickers[stock]\n",
    "    # Get the sector of the current stock\n",
    "    sector = ticker.info.get('sector')\n",
    "    # Determine the number of stocks in this sector; if no sector info, default to 1\n",
    "    sector_count = len(industry[sector]) if sector is not None else 1\n",
    "    # For each stock in twii_tickers.symbols, assign weight = 1/sector_count if it belongs to the same sector, else 0.0\n",
    "    relation = [1.0 / sector_count if other_stock in industry[sector] else 0.0 for other_stock in twii_tickers.symbols]\n",
    "    industry_classification.append(relation)\n",
    "\n",
    "# Save the relation matrix as a text file for inspection and as a numpy file for use in GCN\n",
    "with open(f\"{TARGET_DIR}/industry_classification.txt\", \"w\") as f:\n",
    "    for row in industry_classification:\n",
    "        # Each value is formatted to two decimal places\n",
    "        f.write(' '.join([f'{num:.2f}' for num in row]) + '\\n')\n",
    "\n",
    "# Convert the relation matrix to a numpy array with shape [num_stocks, num_stocks]\n",
    "industry_classification = np.array(industry_classification)\n",
    "print(industry_classification.shape)\n",
    "np.save(f\"{TARGET_DIR}/industry_classification.npy\", industry_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 49)\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = np.corrcoef(ror_df)\n",
    "print(correlation_matrix.shape)\n",
    "np.save(f\"{TARGET_DIR}/industry_classification.npy\", correlation_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepTrader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
